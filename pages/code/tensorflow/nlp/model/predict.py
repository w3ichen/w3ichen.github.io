import tensorflow as tf
import pickle
#MOVIE####################
movieModel = tf.keras.models.load_model('model/movie.h5',compile=False)
with open("model/movieVocab.pickle", "rb") as movieVocabFile:
	movieVocab = pickle.load(movieVocabFile)
movieVocab = {k:(v+3) for k,v in movieVocab.items()} # move by 3 places
movieVocab["<PAD>"] = 0
movieVocab["<START>"] = 1
movieVocab["<UNK>"] = 2
movieVocab["<UNUSED>"] = 3
#SHAKESPEARE##############
shakespeareModel = tf.keras.models.load_model('model/shakespeare.h5',compile=False)
#POTTER###################
potterModel = tf.keras.models.load_model('model/potter.h5',compile=False)
#SPAM#####################
spamModel = tf.keras.models.load_model('model/spam.h5',compile=False)
with open("model/spamVocab.pickle","rb") as spamVocabFile:
	spamVocab = pickle.load(spamVocabFile)
#ENGLISH##################
englishModel = tf.keras.models.load_model('model/englishSentence.h5',compile=False)
##########################

def moviePredict(text):
	# remove all symbols
	text = text.replace(",","").replace(".","").replace("(","").replace(")","").replace(":","").replace("\"","").strip().split(" ")
	encoded = [1]
	for word in text:
		if word.lower() in movieVocab:
			encoded.append(movieVocab[word.lower()])
		else:
			encoded.append(2)
	encoded = tf.keras.preprocessing.sequence.pad_sequences([encoded], value=movieVocab["<PAD>"], padding="post")
	moviePrediction = movieModel.predict(encoded)
	return moviePrediction
def shakespearePredict(numChars, startString):
	char2num = {'\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, "'": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}
	num2char = list(char2num.keys())
	startStringCopy = startString
	# 1. Convert start string to integers
	startString = [char2num[char] for char in startString]
	startString = tf.expand_dims(startString,0)
	# 2. Empty list to store results
	text_generated = []
	# 3. Reset batch size == 1
	shakespeareModel.reset_states()
	# 4. loop through words to generate
	for i in range(int(numChars)):
		predictions = shakespeareModel(startString)
		predictions = tf.squeeze(predictions, 0) # remove batch dimension
		predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()
		startString = tf.expand_dims([predicted_id], 0)
		text_generated.append(num2char[predicted_id])
	return (startStringCopy + ''.join(text_generated))

def potterPredict(numChars, startString):
	char2num = {'\t': 0, '\n': 1, '\x0c': 2, '\r': 3, ' ': 4, '!': 5, '"': 6, '&': 7, "'": 8, '(': 9, ')': 10, '*': 11, ',': 12, '-': 13, '.': 14, '/': 15, '0': 16, '1': 17, '2': 18, '3': 19, '4': 20, '5': 21, '6': 22, '7': 23, '8': 24, '9': 25, ':': 26, ';': 27, '<': 28, '=': 29, '>': 30, '?': 31, 'A': 32, 'B': 33, 'C': 34, 'D': 35, 'E': 36, 'F': 37, 'G': 38, 'H': 39, 'I': 40, 'J': 41, 'K': 42, 'L': 43, 'M': 44, 'N': 45, 'O': 46, 'P': 47, 'Q': 48, 'R': 49, 'S': 50, 'T': 51, 'U': 52, 'V': 53, 'W': 54, 'X': 55, 'Y': 56, 'Z': 57, '[': 58, '\\': 59, ']': 60, '^': 61, '_': 62, '`': 63, 'a': 64, 'b': 65, 'c': 66, 'd': 67, 'e': 68, 'f': 69, 'g': 70, 'h': 71, 'i': 72, 'j': 73, 'k': 74, 'l': 75, 'm': 76, 'n': 77, 'o': 78, 'p': 79, 'q': 80, 'r': 81, 's': 82, 't': 83, 'u': 84, 'v': 85, 'w': 86, 'x': 87, 'y': 88, 'z': 89, '|': 90, '}': 91, '~': 92, '\xad': 93, 'ÃŸ': 94, 'Ã©': 95, 'Ã¼': 96, 'â€“': 97, 'â€”': 98, 'â€˜': 99, 'â€™': 100, 'â€œ': 101, 'â€': 102, 'â€¢': 103, 'â€¦': 104}
	num2char = list(char2num.keys())
	startStringCopy = startString
	# 1. Convert start string to integers
	startString = [char2num[char] for char in startString]
	startString = tf.expand_dims(startString,0)
	# 2. Empty list to store results
	text_generated = []
	# 3. Reset batch size == 1
	potterModel.reset_states()
	# 4. loop through words to generate
	for i in range(int(numChars)):
		predictions = potterModel(startString)
		predictions = tf.squeeze(predictions, 0) # remove batch dimension
		predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()
		startString = tf.expand_dims([predicted_id], 0)
		text_generated.append(num2char[predicted_id])
	return (startStringCopy + ''.join(text_generated))
def spamPredict(text):
	encoded = [1]
	# remove all symbols
	text = text.replace(",","").replace(".","").replace("(","").replace(")","").replace(":","").replace("\"","").strip().split(" ")
	for word in text:
		if word.isnumeric() == True:
		  # if it's a number
		  encoded.append(spamVocab["NUMBER"]) 
		elif (word.startswith("http")) or (word.startswith("www")):
			# if it's a link/URL
		  encoded.append(spamVocab["URL"])
		elif word.lower() in spamVocab:
		  encoded.append(spamVocab[word.lower()])
		else:
		  encoded.append(2) # unknown word
	# pad sequence
	encoded = tf.keras.preprocessing.sequence.pad_sequences([encoded], value=spamVocab["<PAD>"], padding="post")
	return spamModel.predict([encoded])
def englishPredict(startString):
	char2num = {'\t': 0, '\n': 1, ' ': 2, '!': 3, '"': 4, '#': 5, '$': 6, '%': 7, '&': 8, "'": 9, '(': 10, ')': 11, '*': 12, '+': 13, ',': 14, '-': 15, '.': 16, '/': 17, '0': 18, '1': 19, '2': 20, '3': 21, '4': 22, '5': 23, '6': 24, '7': 25, '8': 26, '9': 27, ':': 28, ';': 29, '<': 30, '=': 31, '>': 32, '?': 33, '@': 34, 'A': 35, 'B': 36, 'C': 37, 'D': 38, 'E': 39, 'F': 40, 'G': 41, 'H': 42, 'I': 43, 'J': 44, 'K': 45, 'L': 46, 'M': 47, 'N': 48, 'O': 49, 'P': 50, 'Q': 51, 'R': 52, 'S': 53, 'T': 54, 'U': 55, 'V': 56, 'W': 57, 'X': 58, 'Y': 59, 'Z': 60, '[': 61, ']': 62, '^': 63, '_': 64, '`': 65, 'a': 66, 'b': 67, 'c': 68, 'd': 69, 'e': 70, 'f': 71, 'g': 72, 'h': 73, 'i': 74, 'j': 75, 'k': 76, 'l': 77, 'm': 78, 'n': 79, 'o': 80, 'p': 81, 'q': 82, 'r': 83, 's': 84, 't': 85, 'u': 86, 'v': 87, 'w': 88, 'x': 89, 'y': 90, 'z': 91, '{': 92, '}': 93, '~': 94, '\xa0': 95, 'Â¢': 96, 'Â£': 97, 'Â¥': 98, 'Â«': 99, '\xad': 100, 'Â°': 101, 'Â²': 102, 'Â³': 103, 'Â´': 104, 'Â·': 105, 'Â¹': 106, 'Âº': 107, 'Â»': 108, 'Â¼': 109, 'Â½': 110, 'Ã€': 111, 'Ã': 112, 'Ã…': 113, 'Ã‡': 114, 'Ã‰': 115, 'Ã': 116, 'Ã–': 117, 'Ã—': 118, 'Ã˜': 119, 'Ãš': 120, 'Ãœ': 121, 'ÃŸ': 122, 'Ã ': 123, 'Ã¡': 124, 'Ã¢': 125, 'Ã£': 126, 'Ã¤': 127, 'Ã¥': 128, 'Ã¦': 129, 'Ã§': 130, 'Ã¨': 131, 'Ã©': 132, 'Ãª': 133, 'Ã«': 134, 'Ã¬': 135, 'Ã­': 136, 'Ã®': 137, 'Ã¯': 138, 'Ã°': 139, 'Ã±': 140, 'Ã³': 141, 'Ã´': 142, 'Ã¶': 143, 'Ã¸': 144, 'Ãº': 145, 'Ã»': 146, 'Ã¼': 147, 'Ã¾': 148, 'Ä': 149, 'Äƒ': 150, 'Ä‡': 151, 'Äˆ': 152, 'Ä‰': 153, 'Ä‹': 154, 'ÄŒ': 155, 'Ä': 156, 'Ä‘': 157, 'Ä’': 158, 'Ä“': 159, 'Ä™': 160, 'Ä': 161, 'ÄŸ': 162, 'Ä¥': 163, 'Ä«': 164, 'Ä°': 165, 'Ä±': 166, 'Äµ': 167, 'Å': 168, 'Å‚': 169, 'Å„': 170, 'Å†': 171, 'Å': 172, 'Å': 173, 'Å‘': 174, 'Å“': 175, 'Å›': 176, 'Å': 177, 'ÅŸ': 178, 'Å¡': 179, 'Å«': 180, 'Å­': 181, 'Åº': 182, 'Å¼': 183, 'Å¾': 184, 'Ç': 185, 'Ç': 186, 'Ç”': 187, 'Ç­': 188, 'È™': 189, 'É™': 190, 'É£': 191, 'Ê°': 192, 'Ê»': 193, 'Ê¼': 194, 'Ëˆ': 195, 'Î£': 196, 'Î¤': 197, 'Î©': 198, 'Î±': 199, 'Î²': 200, 'Î³': 201, 'Îµ': 202, 'Î¶': 203, 'Îº': 204, 'Î¼': 205, 'Î½': 206, 'Î¿': 207, 'Ï€': 208, 'Ï„': 209, 'Ğœ': 210, 'Ğ¡': 211, 'Ğ¢': 212, 'Ğ§': 213, 'Ğ°': 214, 'Ğ²': 215, 'Ğ³': 216, 'Ğ´': 217, 'Ğµ': 218, 'Ğ·': 219, 'Ğ¸': 220, 'Ğ¹': 221, 'Ğº': 222, 'Ğ»': 223, 'Ğ½': 224, 'Ğ¾': 225, 'Ñ€': 226, 'Ñ': 227, 'Ñ‚': 228, 'Ñƒ': 229, 'Ñ‡': 230, 'Ñ‹': 231, 'ÑŒ': 232, 'Ñ': 233, 'Ñ': 234, 'Ñ”': 235, 'Ñ—': 236, '×': 237, '×‚': 238, '×': 239, '×™': 240, '×œ': 241, '×Ÿ': 242, '×¢': 243, '×¥': 244, 'ØŸ': 245, 'Ø£': 246, 'Ø¦': 247, 'Ø§': 248, 'Ø©': 249, 'Øª': 250, 'Ø®': 251, 'Ø±': 252, 'Ø·': 253, 'Ù„': 254, 'Ù‘': 255, 'à¤¨': 256, 'à¤ª': 257, 'à¤²': 258, 'à¤¾': 259, 'à¥€': 260, 'à¥‡': 261, 'áµ—': 262, 'á¸': 263, 'á¸¥': 264, 'á¹ƒ': 265, 'á¹‡': 266, 'á¹š': 267, 'á¹›': 268, 'á¹£': 269, 'á¹­': 270, 'áº“': 271, 'áº½': 272, 'á»“': 273, 'á»©': 274, '\u200a': 275, '\u200b': 276, '\u200e': 277, '\u200f': 278, 'â€': 279, 'â€‘': 280, 'â€“': 281, 'â€”': 282, 'â€•': 283, 'â€˜': 284, 'â€™': 285, 'â€œ': 286, 'â€': 287, 'â€¦': 288, '\u202f': 289, 'â€³': 290, 'â€½': 291, 'â°': 292, 'â‚‚': 293, 'â‚£': 294, 'â‚¤': 295, 'â‚©': 296, 'â‚ª': 297, 'â‚«': 298, 'â‚¬': 299, 'â‚°': 300, 'â‚³': 301, 'â‚´': 302, 'â‚µ': 303, 'â‚¹': 304, 'â„¢': 305, 'â†’': 306, 'âˆ’': 307, 'âˆš': 308, 'âŠ‚': 309, 'â–¡': 310, 'â˜‰': 311, 'â˜­': 312, 'â¨¯': 313, 'âµ¥': 314, 'ã€…': 315, 'ã‚': 316, 'ã‚¦': 317, 'ã‚¨': 318, 'ã‚¹': 319, 'ãƒˆ': 320, 'ãƒ¬': 321, 'ãƒ»': 322, 'ãƒ¼': 323, 'ä¸‰': 324, 'ä¸': 325, 'ä¹ˆ': 326, 'ä»€': 327, 'å‚³': 328, 'å…¸': 329, 'å‹™': 330, 'å•': 331, 'åœ‹': 332, 'å¤Ÿ': 333, 'å¤¢': 334, 'æ”¿': 335, 'æ˜': 336, 'æ¨“': 337, 'æ°´': 338, 'æ¸¯': 339, 'æ»¸': 340, 'æ¼”': 341, 'ç”š': 342, 'ç²µ': 343, 'ç´…': 344, 'ç¾©': 345, 'è¥¿': 346, 'è¨˜': 347, 'è©': 348, 'èª': 349, 'éŠ': 350, 'é¡§': 351, 'é¦™': 352, 'éº¼': 353, 'ï¼Ÿ': 354, 'ğŸŒ¡': 355, 'ğŸ˜‚': 356, 'ğŸ˜·': 357, 'ğŸ¤’': 358, 'ğŸ¤§': 359, '\U0001f92e': 360, '\U0001f9a0': 361, '\U0001f9fc': 362}
	num2char = list(char2num.keys())
	startStringCopy = startString
	# 1. Convert start string to integers
	startString = [char2num[char] for char in startString]
	startString = tf.expand_dims(startString,0)
	# 2. Empty list to store results
	text_generated = []
	# 3. Reset batch size == 1
	englishModel.reset_states()
	# 4. loop through words to generate
	for i in range(50):
		predictions = englishModel(startString)
		predictions = tf.squeeze(predictions, 0) # remove batch dimension
		predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()
		startString = tf.expand_dims([predicted_id], 0)
		text_generated.append(num2char[predicted_id])
	return (startStringCopy + ''.join(text_generated))